import requests
import csv
import re

# Set your GitLab project ID and access token
PROJECT_ID = 41299063
ACCESS_TOKEN = "glpat-XsRzi9SD8yHJyMavhhh3"

# Define the API endpoint URL
BASE_URL = f"https://gitlab.com/api/v4/projects/{PROJECT_ID}"

# Function to retrieve notes for a specific issue
def get_notes_for_issue(issue_id):
    notes_url = f"{BASE_URL}/issues/{issue_id}/notes"
    response = requests.get(notes_url, headers={"PRIVATE-TOKEN": ACCESS_TOKEN})
    if response.status_code == 200:
        return response.json()
    return []

# Create a CSV file and write the data
with open("all_issues_comments_grouped.csv", mode="w", newline="", encoding="utf-8") as csv_file:
    writer = csv.writer(csv_file)

    # Create headers for Upload Paths
    headers = ["Issue ID", "Upload Paths"]
    writer.writerow(headers)

    page = 1

    while True:
        issues_url = f"{BASE_URL}/issues?per_page=100&page={page}"
        response = requests.get(issues_url, headers={"PRIVATE-TOKEN": ACCESS_TOKEN})
        
        if response.status_code != 200:
            print(f"Failed to retrieve issues. Status code: {response.status_code}")
            break
        
        issues_data = response.json()
        
        if not issues_data:
            break  # No more issues to retrieve

        for issue in issues_data:
            issue_id = issue["id"]
            notes = get_notes_for_issue(issue_id)
            upload_paths = []

            for note in notes:
                body = note["body"]
                uploads = re.findall(r'/uploads/[^)]*', body)
                upload_paths.extend(uploads)

            # Add the prefix to each upload path
            prefix = 'file://csvimport/'
            upload_paths = [prefix + path for path in upload_paths]

            # Write data to CSV
            row_data = [issue_id, ",".join(upload_paths)]
            writer.writerow(row_data)

        page += 1

print("Data has been saved to all_issues_comments_grouped.csv")
